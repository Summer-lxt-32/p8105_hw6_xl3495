---
title: "p8105_hw6_xl3495"
author: "Xueting Li"
date: "2024-12-01"
output: github_document
---

```{r}
library(tidyverse)
library(modelr)
library(broom)
library(purrr)
set.seed(123)
```



# Problem 1

```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```
```{r}
n_bootstrap = 5000

boot_models = weather_df |>
  select(tmax, tmin) |>
  modelr::bootstrap(n = n_bootstrap) |>
    mutate(
    model = map(strap, ~ lm(tmax ~ tmin, data = .))
  )

boot_r_squared = boot_models |>
  mutate(glance = map(model, glance)) |>
  unnest(glance) |>
  select(r.squared) |>
   mutate(metric = "R-squared")


boot_coefficients = boot_models |>
  mutate(
    coefficients = map(model, coefficients),
    product = map_dbl(coefficients, ~ .[1] * .[2]),
    log_beta = log(product)
  ) |>
  select(log_beta) |>
  mutate(metric = "log(β0 * β1)")
```

```{r}
combined_data = bind_rows(
  boot_r_squared |> rename(value = r.squared),
  boot_coefficients |> rename(value = log_beta)
)

ggplot(combined_data, aes(x = value, fill = metric)) +
  geom_histogram(bins = 30, alpha = 0.6) +
  facet_wrap(~ metric, scales = "free_x") +  # Facet by 'metric' variable
  theme_minimal() +
  scale_fill_manual(values = c("R-squared" = "lightblue", "log(β0 * β1)" = "lightgreen")) +
  labs(
    title = "Distribution of R-squared and log(β0 * β1) from Bootstrap Samples",
    x = "Value", y = "Frequency"
  )
```
From the plot, the distributions of the two estimates follow an approximate normal distribution. For $log(\beta_0 * \beta_1)$, it frequently distributes between (2, 2.025). For, $r^2$,it frequently distributes between (0.905, 0.915).

```{r}
r_squared_ci = quantile(boot_r_squared$r.squared, probs = c(0.025, 0.975))

log_beta_ci = quantile(boot_coefficients$log_beta, probs = c(0.025, 0.975))

ci_df = data.frame(
  Metric = c("R-squared", "log(β0 * β1)"),
  Lower_bound = c(r_squared_ci[1], log_beta_ci[1]),
  Upper_bound = c(r_squared_ci[2], log_beta_ci[2])
)

print(ci_df)
```


# Problem 2

```{r}
homicide_data = read_csv("datasets/homicide-data.csv") |>
  mutate(
    city_state = paste(city, state, sep = ", "),
    homicide_solved = if_else(disposition == "Closed by arrest", 1, 0),
    victim_age = as.numeric(victim_age)
    ) |>
  filter(
    !city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL"),
    victim_race %in% c("White", "Black"),
    !is.na(victim_age)
    )
```
```{r}
baltimore_data = homicide_data |>
  filter(city_state == "Baltimore, MD")

log_reg_model = glm(homicide_solved ~ victim_age + victim_sex + victim_race, 
                     data = baltimore_data, 
                     family = binomial)

model_summary = tidy(log_reg_model, conf.int = TRUE)

# Extract the estimate and confidence interval for victim_sex variable
sex_results = model_summary |>
  filter(term == "victim_sexMale")

odds_ratio = exp(sex_results$estimate)
lower_ci = exp(sex_results$conf.low)
upper_ci = exp(sex_results$conf.high)

result_table = tibble(
  Variable = "Male vs Female Victims",
  Odds_Ratio = odds_ratio,
  Lower_CI = lower_ci,
  Upper_CI = upper_ci
)

print(result_table)
```


```{r}
city_log_reg = homicide_data |>
  filter(
    victim_sex %in% c("Male", "Female"), victim_race %in% c("White", "Black")
    ) |>
  group_by(city) |>
  nest() |>
  mutate(
    model = map(data, ~ glm(homicide_solved ~ victim_age + victim_sex + victim_race, 
                            data = ., family = binomial)),
    tidy_results = map(model, tidy, conf.int = TRUE)
  )


city_or_results = city_log_reg |>
  unnest(tidy_results) |>
  filter(term == "victim_sexMale") |>
  mutate(
    odds_ratio = exp(estimate),
    lower_ci = exp(conf.low),
    upper_ci = exp(conf.high)
  ) |>
  select(city, odds_ratio, lower_ci, upper_ci) |>
  arrange(desc(odds_ratio))

head(city_or_results)
```


```{r}
ggplot(city_or_results, aes(x = reorder(city, odds_ratio), 
                            y = odds_ratio, 
                            ymin = lower_ci, 
                            ymax = upper_ci)) +
  geom_point() + 
  geom_errorbar(width = 0.3) +
  coord_flip() +
  labs(
    title = "Adjusted Odds Ratio for Solving Homicides: Male vs Female Victims by City",
    x = "City",
    y = "Adjusted Odds Ratio (Male vs Female)"
  ) +
  theme_minimal()
```

According to the plot,  if the point is above 1, it suggests that male victims have a higher likelihood of having their homicide solved compared to female victims in that city, and if the CI includes 1, the effect is not statistically significant, meaning we cannot conclude whether there's a difference in the likelihood of solving homicides for male vs. female victims in that city. For example, male victims in Albuquerque have a higher likelihood of having their homicide solved compared to female victims. There are still a number of cities we cannot conclude whether there's a difference in the likelihood of solving homicides for male vs. female victims.

# Problem 3

```{r}
bw_data = read_csv("datasets/birthweight.csv") |>
  mutate(
    babysex = factor(babysex, levels = c(1, 2), labels = c("Male", "Female")),
    frace = factor(frace, levels = c(1, 2, 3, 4, 8, 9),
                   labels = c("White", "Black", "Asian", "Puerto Rican", "Other", "Unknown")),
    mrace = factor(mrace, levels = c(1, 2, 3, 4, 8),
                   labels = c("White", "Black", "Asian", "Puerto Rican", "Other")),
    malform = factor(malform, levels = c(0, 1), labels = c("Absent", "Present"))
  ) |>
  na.omit()

summary(bw_data)
```
## Model1: delwt + momage + ppbmi

```{r}
model1 = lm(bwt ~ delwt + momage + ppbmi, data = bw_data)
summary(model1)
model1 |>
  broom::tidy()
```

```{r}
bw_data |>
  add_predictions(model1) |>
  add_residuals(model1) |>
  ggplot(aes(x = pred, y = resid)) +
  geom_point(alpha = 0.3) +
  geom_smooth(method = "lm", color = "blue") +
  labs(x = "Fitted Values", y = "Residuals", 
       title = "Residuals vs Fitted Values for Model 1")
```

The modeling process involves building a linear regression model to predict birthweight (bwt) based on several predictor variables. In this case, I am using the following variables:

`delwt`: Mother's weight at delivery (in pounds)  
`momage`: Mother's age at delivery (in years)  
`ppbmi`: Mother's pre-pregnancy BMI  

This model aims to predict the birthweight (bwt) using these predictors, based on a linear relationship. After summarizing the model with summary() and broom::tidy(), I used add_predictions() and add_residuals() to compute predicted values and residuals.

## Model2: blength + gaweeks

```{r}
model2 = lm(bwt ~ blength + gaweeks, data = bw_data)
summary(model2)
```

```{r}
bw_data |>
  add_predictions(model2) |>
  add_residuals(model2) |>
  ggplot(aes(x = pred, y = resid)) +
  geom_point(alpha = 0.3) +
  geom_smooth(method = "lm", color = "blue") +
  labs(x = "Fitted Values", y = "Residuals", 
       title = "Residuals vs Fitted Values for Model 2")
```

## Model3: bhead * blength * babysex

```{r}
model3 = lm(bwt ~ bhead * blength * babysex, data = bw_data)
summary(model3)
```

```{r}
bw_data |>
  add_predictions(model3) |>
  add_residuals(model3) |>
  ggplot(aes(x = pred, y = resid)) +
  geom_point(alpha = 0.3) +
  geom_smooth(method = "lm", color = "blue") +
  labs(x = "Fitted Values", y = "Residuals", 
       title = "Residuals vs Fitted Values for Model 3")
```

## Cross Validation

```{r}
cv_df = crossv_mc(bw_data, n = 100, test = 0.2) |>
  mutate(
    model1  = map(train, \(df) lm(bwt ~ delwt + momage + ppbmi, data = bw_data)),
    model2  = map(train, \(df) lm(bwt ~ blength + gaweeks, data = bw_data)),
    model3 = map(train, \(df) lm(bwt ~ bhead * blength * babysex, data = bw_data))
  ) |>
   mutate(
    rmse_model1 = map2_dbl(model1, test, ~rmse(model = .x, data = .y)),
    rmse_model2 = map2_dbl(model2, test, ~rmse(model = .x, data = .y)),
    rmse_model3 = map2_dbl(model3, test, ~rmse(model = .x, data = .y))
  )

cv_df |> 
  summarise(model1_mean_error = mean(rmse_model1),
            model2_mean_error = mean(rmse_model2),
            model3_mean_error = mean(rmse_model3)) |>
  knitr::kable(digits = 3)
```


```{r}
cv_long = cv_df |>
  pivot_longer(cols = starts_with("rmse_model"), 
               names_to = "model", 
               values_to = "rmse")

ggplot(cv_long, aes(x = model, y = rmse, fill = model)) +
  geom_violin(trim = FALSE) + 
  labs(
    title = "Cross Validation: RMSE Distribution",
    x = "Model",
    y = "RMSE"
  ) +
  scale_fill_brewer(palette = "Set3") + 
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

My model shows poorest performance in predicting birthweight with the highest mean squared error, but model 3 has a good performance among the three with lowest mse.














